import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer, WordNetLemmatizer
import string

# Download necessary NLTK data files
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Initialize the stemmer and lemmatizer
stemmer = PorterStemmer()
lemmatizer = WordNetLemmatizer()

# Function to preprocess text
def preprocess_text(text):
    # Lowercasing
    text = text.lower()
    
    # Removing punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    # Tokenization
    words = word_tokenize(text)
    
    # Removing stopwords
    stop_words = set(stopwords.words('english'))
    words = [word for word in words if word not in stop_words]
    
    # Stemming
    words_stemmed = [stemmer.stem(word) for word in words]
    
    # Lemmatization
    words_lemmatized = [lemmatizer.lemmatize(word) for word in words_stemmed]
    
    # Join words back to a single string
    preprocessed_text = ' '.join(words_lemmatized)
    
    return preprocessed_text

# Example usage
if __name__ == "__main__":
    text = "The company's revenue for the first quarter increased significantly compared to the previous year."
    preprocessed_text = preprocess_text(text)
    print(f"Preprocessed text: {preprocessed_text}")

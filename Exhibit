import re
import pdfplumber
import tabula
import pandas as pd

# Function to extract information based on the description
def extract_info(description):
    # Extract Sub/Non Sub
    if "Subsidized" in description:
        sub_non_sub = "Subsidized"
    elif "Non-Subsidized" in description:
        sub_non_sub = "Non Subsidized"
    else:
        sub_non_sub = "Not Extracted"

    # Extract Program Type
    if "Low rate Program" in description:
        program_type = "Low rate"
    else:
        program_type = "Not Extracted"

    # Extract Program Location
    match = re.search(r'(\d{2}MY.*?)(?=[ .,]|$)', description)
    program_location = match.group(0) if match else "Not Extracted"

    # Extract Dates
    date_match = re.search(r'(\w+ \d{1,2}, \d{4}) - (\w+ \d{1,2}, \d{4})', description)
    if date_match:
        start_date = date_match.group(1)
        end_date = date_match.group(2)
    else:
        start_date = end_date = "Not Extracted"

    return sub_non_sub, program_type, program_location, start_date, end_date

# Path to the PDF file
pdf_path = '/mnt/data/your_pdf_file.pdf'

# Extract all tables from the PDF using tabula
tables = tabula.read_pdf(pdf_path, pages='all', multiple_tables=True)

# Initialize an empty DataFrame to store all tables
all_tables = pd.DataFrame()

with pdfplumber.open(pdf_path) as pdf:
    for page_num, page in enumerate(pdf.pages, start=1):
        # Extract the text from the page
        text = page.extract_text()
        paragraphs = text.split('\n')
        
        # Process each table on the page
        page_tables = tables[page_num - 1]
        
        for table in page_tables:
            # Convert the table to a DataFrame
            df = pd.DataFrame(table[1:], columns=table[0])
            
            # Extract all paragraphs above the table
            # Find the index of the table in the text
            table_start_index = text.find(table[0][0])
            
            # Find the text before the table
            description = text[:table_start_index].strip()
            
            # Extract the additional columns based on the description
            sub_non_sub, program_type, program_location, start_date, end_date = extract_info(description)
            
            # Add the additional columns to the DataFrame
            df['Sub/Non Sub'] = sub_non_sub
            df['Program Type'] = program_type
            df['Program Location'] = program_location
            df['Start Date'] = start_date
            df['End Date'] = end_date
            
            # Append the DataFrame to the list of all tables
            all_tables = pd.concat([all_tables, df], ignore_index=True)

# Save the final table to a CSV file
all_tables.to_csv('/mnt/data/extracted_tables.csv', index=False)
